{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Loneliness.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOJM3Rt3IOUfIClXkmNknv5"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nIJXsR7qiUZT","executionInfo":{"status":"ok","timestamp":1609642308427,"user_tz":-480,"elapsed":35905,"user":{"displayName":"Dedy Farhamsa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GizmlqZ1fH7Sex_yKEsgk6gAqtjsbO22XkY2CBuJw=s64","userId":"01928714727866782397"}},"outputId":"0062ee75-9146-4970-ee7c-0bfd13cce627"},"source":["from google.colab import drive\r\n","drive.mount('/content/gdrive/')\r\n","import sys\r\n","path = '/content/gdrive/MyDrive/Colab Notebooks/Santi/'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive/\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"r3W8Q0oAxaXH"},"source":["TTGDS: Total Depresion\r\n","TTLSS : Total Social Suport\r\n","Method quistioner TTLN UCLA"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":248},"id":"1neJGluXjEPc","executionInfo":{"status":"ok","timestamp":1609642327475,"user_tz":-480,"elapsed":2417,"user":{"displayName":"Dedy Farhamsa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GizmlqZ1fH7Sex_yKEsgk6gAqtjsbO22XkY2CBuJw=s64","userId":"01928714727866782397"}},"outputId":"d9386eea-ecc1-4f6b-e103-7baa5c61fe3f"},"source":["import pandas as pd\r\n","from pandas import read_csv\r\n","datasetOri = read_csv(path+\"depression.csv\")\r\n","#n = len(dataset)\r\n","datasetOri.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>VAR00001</th>\n","      <th>Birthday</th>\n","      <th>Age</th>\n","      <th>Gender</th>\n","      <th>Race</th>\n","      <th>Religion</th>\n","      <th>EduLevel</th>\n","      <th>MaritalStatus</th>\n","      <th>NumberOfChildren</th>\n","      <th>LivingStatus</th>\n","      <th>EmployedNow</th>\n","      <th>Jobnow</th>\n","      <th>EmployeBefore</th>\n","      <th>PastJob</th>\n","      <th>Income</th>\n","      <th>IncomeMonthlyCost</th>\n","      <th>VisitCHCTmsYears</th>\n","      <th>LeisureActivity</th>\n","      <th>AttendLAtimesMonth</th>\n","      <th>Comorbidity</th>\n","      <th>HealthCondition</th>\n","      <th>HearingProblem</th>\n","      <th>HearingAids</th>\n","      <th>VisualProblem</th>\n","      <th>WhatVisualProblem</th>\n","      <th>PermanentTeeth</th>\n","      <th>OralStatus</th>\n","      <th>Medication</th>\n","      <th>ADLSBarthelIndex</th>\n","      <th>IADLSLawton</th>\n","      <th>CogFunctionSPMSQ</th>\n","      <th>S1</th>\n","      <th>S2</th>\n","      <th>S3</th>\n","      <th>S4</th>\n","      <th>S5</th>\n","      <th>S6</th>\n","      <th>S7</th>\n","      <th>S8</th>\n","      <th>S9</th>\n","      <th>...</th>\n","      <th>RL10</th>\n","      <th>RL15</th>\n","      <th>RL16</th>\n","      <th>RL19</th>\n","      <th>RL20</th>\n","      <th>TTUCLA</th>\n","      <th>RD1</th>\n","      <th>RD2</th>\n","      <th>RD3</th>\n","      <th>RD4</th>\n","      <th>RD5</th>\n","      <th>RD6</th>\n","      <th>RD7</th>\n","      <th>RD8</th>\n","      <th>RD9</th>\n","      <th>RD10</th>\n","      <th>RD11</th>\n","      <th>RD12</th>\n","      <th>RD13</th>\n","      <th>RD14</th>\n","      <th>RD15</th>\n","      <th>TTGDS</th>\n","      <th>RG</th>\n","      <th>RR</th>\n","      <th>RL</th>\n","      <th>RE</th>\n","      <th>RM</th>\n","      <th>RLv</th>\n","      <th>REn</th>\n","      <th>REB</th>\n","      <th>RICom</th>\n","      <th>RHP</th>\n","      <th>RVP</th>\n","      <th>RPT</th>\n","      <th>NewRPT</th>\n","      <th>RHP2</th>\n","      <th>HP3</th>\n","      <th>Rcomor</th>\n","      <th>CatGDS</th>\n","      <th>CatGDS2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>195908</td>\n","      <td>60</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>2</td>\n","      <td>8</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>400000</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>95</td>\n","      <td>6</td>\n","      <td>10</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>6</td>\n","      <td>6</td>\n","      <td>6</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>...</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>48</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>10</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>195803</td>\n","      <td>61</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>400000</td>\n","      <td>2</td>\n","      <td>12</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>95</td>\n","      <td>8</td>\n","      <td>10</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>6</td>\n","      <td>6</td>\n","      <td>6</td>\n","      <td>5</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>...</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>48</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>9</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>195807</td>\n","      <td>61</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>400000</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>95</td>\n","      <td>7</td>\n","      <td>4</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>...</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>54</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>8</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>195302</td>\n","      <td>66</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>500000</td>\n","      <td>2</td>\n","      <td>9</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>85</td>\n","      <td>0</td>\n","      <td>10</td>\n","      <td>7</td>\n","      <td>7</td>\n","      <td>7</td>\n","      <td>6</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>6</td>\n","      <td>6</td>\n","      <td>6</td>\n","      <td>...</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>56</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>9</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>195704</td>\n","      <td>62</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>500000</td>\n","      <td>2</td>\n","      <td>8</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>95</td>\n","      <td>8</td>\n","      <td>4</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>6</td>\n","      <td>6</td>\n","      <td>6</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>47</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>9</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows Ã— 124 columns</p>\n","</div>"],"text/plain":["   VAR00001  Birthday  Age  Gender  Race  ...  RHP2  HP3  Rcomor  CatGDS  CatGDS2\n","0         1    195908   60       1     2  ...     0    0       1       1        1\n","1         2    195803   61       1     2  ...     0    0       1       1        1\n","2         3    195807   61       1     2  ...     0    0       0       1        1\n","3         4    195302   66       1     1  ...     0    0       1       1        1\n","4         5    195704   62       2     3  ...     0    0       1       1        1\n","\n","[5 rows x 124 columns]"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"code","metadata":{"id":"s-e3Y0k7qWYY","executionInfo":{"status":"ok","timestamp":1609661005608,"user_tz":-480,"elapsed":1033,"user":{"displayName":"Dedy Farhamsa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GizmlqZ1fH7Sex_yKEsgk6gAqtjsbO22XkY2CBuJw=s64","userId":"01928714727866782397"}}},"source":["from sklearn.preprocessing import MinMaxScaler\r\n","\r\n","interestColumn = ['Age', 'Gender', 'EduLevel', 'NumberOfChildren','LivingStatus',\r\n","                  'HealthCondition', 'HearingProblem', 'OralStatus', 'PermanentTeeth', 'Medication',\r\n","                  'ADLSBarthelIndex', 'IADLSLawton', 'CogFunctionSPMSQ', 'TTGDS']\r\n","dataset = datasetOri[interestColumn]"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ko8pdx8sLQdp","executionInfo":{"status":"ok","timestamp":1609661016438,"user_tz":-480,"elapsed":1425,"user":{"displayName":"Dedy Farhamsa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GizmlqZ1fH7Sex_yKEsgk6gAqtjsbO22XkY2CBuJw=s64","userId":"01928714727866782397"}},"outputId":"4b67ff6e-d8d2-4ef4-b02c-31a1c57573f4"},"source":["import numpy as np\r\n","\r\n","X = dataset.iloc[:, :-1].values\r\n","Y = dataset.iloc[:, 12].values\r\n","from sklearn.preprocessing import OneHotEncoder\r\n","from sklearn.compose import ColumnTransformer\r\n","transformer = ColumnTransformer(\r\n","        [('encoder', OneHotEncoder(), [1])],\r\n","        remainder='passthrough')\r\n","X = np.array(transformer.fit_transform(X), dtype=np.float)\r\n","\r\n","# Saat ini column gender pindah ke kolom 1 dan 2, kolom 1 laki2 kolom 2 perempuan (true false)\r\n","# Test uji 4 data X:[Age\tGender\tEduLevel\tNumberOfChildren] terhadap Y:[CogFunctionSPMSQ]\r\n","X = X[:, 1:5]\r\n","print(X)"],"execution_count":28,"outputs":[{"output_type":"stream","text":["[[ 0. 60.  4.  8.]\n"," [ 0. 61.  4.  0.]\n"," [ 0. 61.  4.  3.]\n"," ...\n"," [ 1. 62.  2.  4.]\n"," [ 1. 62.  4.  6.]\n"," [ 1. 65.  1.  6.]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_IKjXQRAOnBg","executionInfo":{"status":"ok","timestamp":1609661027599,"user_tz":-480,"elapsed":1188,"user":{"displayName":"Dedy Farhamsa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GizmlqZ1fH7Sex_yKEsgk6gAqtjsbO22XkY2CBuJw=s64","userId":"01928714727866782397"}}},"source":["# Membagi data menjadi the Training set and Test set (20% ke test set dan 80% ke train set)\r\n","from sklearn.model_selection import train_test_split\r\n","X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 0)\r\n","\r\n","# Membuat model Multiple Linear Regression dari Training set\r\n","from sklearn.linear_model import LinearRegression\r\n","regressor = LinearRegression()\r\n","regressor.fit(X_train, Y_train)\r\n"," \r\n","# Memprediksi hasil Test set\r\n","Y_pred = regressor.predict(X_test)"],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":487},"id":"A24OJYZ6Rac8","executionInfo":{"status":"ok","timestamp":1609661032433,"user_tz":-480,"elapsed":1889,"user":{"displayName":"Dedy Farhamsa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GizmlqZ1fH7Sex_yKEsgk6gAqtjsbO22XkY2CBuJw=s64","userId":"01928714727866782397"}},"outputId":"a1663a21-7fd9-409f-9927-e66b0df07caf"},"source":["import statsmodels.api as sm\r\n","#menambah nilai const (Xo) pada fungsi Regression Y = Xo + a1*X1 + .....\r\n","X_new = sm.add_constant(X)\r\n","X_opt = X_new[:, [0, 1, 2, 3, 4]]\r\n","\r\n","regressor_OLS = sm.OLS(endog = Y, exog = X_opt).fit()\r\n","regressor_OLS.summary()\r\n","#Lihat Lihatlah pada bagian p value nya (P>|t|). variable Xn yg p value nya>0.05 dibuang saja"],"execution_count":30,"outputs":[{"output_type":"execute_result","data":{"text/html":["<table class=\"simpletable\">\n","<caption>OLS Regression Results</caption>\n","<tr>\n","  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.160</td>\n","</tr>\n","<tr>\n","  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.157</td>\n","</tr>\n","<tr>\n","  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   65.33</td>\n","</tr>\n","<tr>\n","  <th>Date:</th>             <td>Sun, 03 Jan 2021</td> <th>  Prob (F-statistic):</th> <td>1.23e-50</td>\n","</tr>\n","<tr>\n","  <th>Time:</th>                 <td>08:03:50</td>     <th>  Log-Likelihood:    </th> <td> -2821.1</td>\n","</tr>\n","<tr>\n","  <th>No. Observations:</th>      <td>  1381</td>      <th>  AIC:               </th> <td>   5652.</td>\n","</tr>\n","<tr>\n","  <th>Df Residuals:</th>          <td>  1376</td>      <th>  BIC:               </th> <td>   5678.</td>\n","</tr>\n","<tr>\n","  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>   \n","</tr>\n","<tr>\n","  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n","</tr>\n","</table>\n","<table class=\"simpletable\">\n","<tr>\n","    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n","</tr>\n","<tr>\n","  <th>const</th> <td>   13.5178</td> <td>    0.591</td> <td>   22.890</td> <td> 0.000</td> <td>   12.359</td> <td>   14.676</td>\n","</tr>\n","<tr>\n","  <th>x1</th>    <td>   -0.2104</td> <td>    0.109</td> <td>   -1.932</td> <td> 0.054</td> <td>   -0.424</td> <td>    0.003</td>\n","</tr>\n","<tr>\n","  <th>x2</th>    <td>   -0.0927</td> <td>    0.008</td> <td>  -11.615</td> <td> 0.000</td> <td>   -0.108</td> <td>   -0.077</td>\n","</tr>\n","<tr>\n","  <th>x3</th>    <td>    0.3224</td> <td>    0.042</td> <td>    7.754</td> <td> 0.000</td> <td>    0.241</td> <td>    0.404</td>\n","</tr>\n","<tr>\n","  <th>x4</th>    <td>-1.406e-05</td> <td>    0.022</td> <td>   -0.001</td> <td> 0.999</td> <td>   -0.043</td> <td>    0.043</td>\n","</tr>\n","</table>\n","<table class=\"simpletable\">\n","<tr>\n","  <th>Omnibus:</th>       <td>238.914</td> <th>  Durbin-Watson:     </th> <td>   1.544</td>\n","</tr>\n","<tr>\n","  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 432.445</td>\n","</tr>\n","<tr>\n","  <th>Skew:</th>          <td>-1.065</td>  <th>  Prob(JB):          </th> <td>1.25e-94</td>\n","</tr>\n","<tr>\n","  <th>Kurtosis:</th>      <td> 4.726</td>  <th>  Cond. No.          </th> <td>    787.</td>\n","</tr>\n","</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."],"text/plain":["<class 'statsmodels.iolib.summary.Summary'>\n","\"\"\"\n","                            OLS Regression Results                            \n","==============================================================================\n","Dep. Variable:                      y   R-squared:                       0.160\n","Model:                            OLS   Adj. R-squared:                  0.157\n","Method:                 Least Squares   F-statistic:                     65.33\n","Date:                Sun, 03 Jan 2021   Prob (F-statistic):           1.23e-50\n","Time:                        08:03:50   Log-Likelihood:                -2821.1\n","No. Observations:                1381   AIC:                             5652.\n","Df Residuals:                    1376   BIC:                             5678.\n","Df Model:                           4                                         \n","Covariance Type:            nonrobust                                         \n","==============================================================================\n","                 coef    std err          t      P>|t|      [0.025      0.975]\n","------------------------------------------------------------------------------\n","const         13.5178      0.591     22.890      0.000      12.359      14.676\n","x1            -0.2104      0.109     -1.932      0.054      -0.424       0.003\n","x2            -0.0927      0.008    -11.615      0.000      -0.108      -0.077\n","x3             0.3224      0.042      7.754      0.000       0.241       0.404\n","x4         -1.406e-05      0.022     -0.001      0.999      -0.043       0.043\n","==============================================================================\n","Omnibus:                      238.914   Durbin-Watson:                   1.544\n","Prob(Omnibus):                  0.000   Jarque-Bera (JB):              432.445\n","Skew:                          -1.065   Prob(JB):                     1.25e-94\n","Kurtosis:                       4.726   Cond. No.                         787.\n","==============================================================================\n","\n","Warnings:\n","[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n","\"\"\""]},"metadata":{"tags":[]},"execution_count":30}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CvGc5-yNZODd","executionInfo":{"status":"ok","timestamp":1609661037202,"user_tz":-480,"elapsed":1080,"user":{"displayName":"Dedy Farhamsa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GizmlqZ1fH7Sex_yKEsgk6gAqtjsbO22XkY2CBuJw=s64","userId":"01928714727866782397"}},"outputId":"85726174-0ca1-4a7e-f0ac-6e5989790446"},"source":["print(regressor_OLS.pvalues)"],"execution_count":31,"outputs":[{"output_type":"stream","text":["[1.60748630e-98 5.36228004e-02 8.07203390e-30 1.71900520e-14\n"," 9.99485322e-01]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3xbodqK0TjHO"},"source":["scaler = MinMaxScaler()\r\n","x_scaled = scaler.fit_transform(x)\r\n","df_temp = pd.DataFrame(x_scaled, columns=column_names_to_normalize, index = df.index)\r\n","x = df[column_names_to_normalize] = df_temp"],"execution_count":null,"outputs":[]}]}